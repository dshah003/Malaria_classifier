{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Diseased Cell Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define path to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()  #Get Path of Current Working Directory\n",
    "\n",
    "infected_train_data = cwd + '/cell_images/Train/infected'\n",
    "uninfected_train_data = cwd + '/cell_images/Train/uninfected'\n",
    "infected_test_data = cwd + '/cell_images/Test/infected'\n",
    "uninfected_test_data = cwd + '/cell_images/Test/uninfected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "size_batch = 50\n",
    "alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(img, label):\n",
    "    if label == 0:\n",
    "        ohl = np.array([1,0])\n",
    "    elif label == 1:\n",
    "        ohl = np.array([0,1])\n",
    "    return ohl\n",
    "\n",
    "def load_train_data():\n",
    "    train_images = []\n",
    "    \n",
    "    label = 0  #For Infected Cells\n",
    "#     print(\"Loading Training data for infected Cells\")\n",
    "    for i in tqdm(os.listdir(infected_train_data)):\n",
    "        path = os.path.join(infected_train_data, i)\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "        except:\n",
    "            print(\"Error Loading this image: \", i) \n",
    "        train_images.append([np.array(img), one_hot_label(i, label)])\n",
    "    \n",
    "    label = 1 #For Uninfected\n",
    "#     print(\"Loading Training data for uninfected Cells\")\n",
    "    for i in tqdm(os.listdir(uninfected_train_data)):\n",
    "        path = os.path.join(uninfected_train_data, i)\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "        except:\n",
    "            print(\"Error Loading this image: \", i) \n",
    "        train_images.append([np.array(img), one_hot_label(i, label)])\n",
    "    \n",
    "    shuffle(train_images) #Shuffle data so every batch gets both, positives and negatives.\n",
    "    shuffle(train_images) #Just to be sure Lol!\n",
    "    return train_images\n",
    "\n",
    "def load_test_data():\n",
    "    test_images = []\n",
    "    \n",
    "    label = 0\n",
    "#     print(\"Loading Test data for infected Cells\")\n",
    "    for i in tqdm(os.listdir(infected_test_data)):\n",
    "        path = os.path.join(infected_test_data, i)\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "        except:\n",
    "            print(\"Error Loading this image: \", i)            \n",
    "        test_images.append([np.array(img), one_hot_label(i, label)])\n",
    "    \n",
    "    label = 1\n",
    "#     print(\"Loading Test data for uninfected Cells\")\n",
    "    for i in tqdm(os.listdir(uninfected_test_data)):\n",
    "        path = os.path.join(uninfected_test_data, i)\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "        except:\n",
    "            print(\"Error Loading this image: \", i)\n",
    "        test_images.append([np.array(img), one_hot_label(i, label)])\n",
    "    return test_images   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12779/12779 [00:07<00:00, 1744.69it/s]\n",
      "100%|██████████| 12779/12779 [00:06<00:00, 1899.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1773.93it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1773.70it/s]\n"
     ]
    }
   ],
   "source": [
    "training_images = load_train_data()\n",
    "testing_images = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[64,64,3]))\n",
    "model.add(Conv2D(filters = 32, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5, padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters = 50, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5, padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters = 80, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5, padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "optimizer = Adam(lr = alpha)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 25558 into shape (25558,64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9ea173885295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_withLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_withLabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25558\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_withLabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 25558 into shape (25558,64,64,1)"
     ]
    }
   ],
   "source": [
    "X_withLabel = np.array(training_images)\n",
    "x_train = X_withLabel[:,0]\n",
    "x_train.reshape([25558,64, 64,1])\n",
    "y_train = X_withLabel[:,1]\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs = num_epochs, batch_size = size_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
